{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric,Dataset,DatasetDict\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import AutoTokenizer\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "#datasets = [\"samsum\",\"cnn\",\"xsum\"]\n",
    "model_name = \"facebook/bart-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    # Extract a few results\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/weichen/.cache/huggingface/modules/datasets_modules/datasets/samsum/3f7dba43be72ab10ca66a2e0f8547b3590e96c2bd9f2cbb1f6bb1ec1f1488ba6 (last modified on Wed Apr 28 13:59:29 2021) since it couldn't be found locally at samsum/samsum.py or remotely (ConnectionError).\n",
      "Reusing dataset samsum (/home/weichen/.cache/huggingface/datasets/samsum/samsum/0.0.0/3f7dba43be72ab10ca66a2e0f8547b3590e96c2bd9f2cbb1f6bb1ec1f1488ba6)\n",
      "Using the latest cached version of the module from /home/weichen/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Wed Apr 28 14:00:09 2021) since it couldn't be found locally at rouge/rouge.py or remotely (ConnectionError).\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"samsum\")\n",
    "metric = load_metric(\"rouge\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 512\n",
    "max_target_length = 128\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [doc for doc in examples[\"dialogue\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"summary\"], max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a89bba56ce4a6dbeb09e81502d0b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13fddc6811994428be16c645b0ce5322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d48fc81baf459fa7a3d4364866957f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    \"BART-LARGE-samsum\",\n",
    "    evaluation_strategy = \"steps\",\n",
    "    eval_steps = 500,\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=5,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    warmup_steps=200,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_rouge1\",\n",
    "    greater_is_better=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weichen/anaconda3/envs/emotion_fan/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='9210' max='9210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9210/9210 1:04:02, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.828700</td>\n",
       "      <td>1.504997</td>\n",
       "      <td>46.025300</td>\n",
       "      <td>23.523500</td>\n",
       "      <td>38.553800</td>\n",
       "      <td>42.304800</td>\n",
       "      <td>18.026900</td>\n",
       "      <td>55.408700</td>\n",
       "      <td>14.763000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.613700</td>\n",
       "      <td>1.471320</td>\n",
       "      <td>47.186800</td>\n",
       "      <td>24.570500</td>\n",
       "      <td>39.975800</td>\n",
       "      <td>43.813200</td>\n",
       "      <td>18.385100</td>\n",
       "      <td>55.597300</td>\n",
       "      <td>14.713000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.575400</td>\n",
       "      <td>1.420214</td>\n",
       "      <td>47.280800</td>\n",
       "      <td>25.574200</td>\n",
       "      <td>40.398900</td>\n",
       "      <td>43.660900</td>\n",
       "      <td>17.316600</td>\n",
       "      <td>55.455400</td>\n",
       "      <td>14.751000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.450400</td>\n",
       "      <td>1.412556</td>\n",
       "      <td>48.142600</td>\n",
       "      <td>25.769800</td>\n",
       "      <td>41.345100</td>\n",
       "      <td>44.688700</td>\n",
       "      <td>17.773800</td>\n",
       "      <td>55.323400</td>\n",
       "      <td>14.786000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.307000</td>\n",
       "      <td>1.411188</td>\n",
       "      <td>47.695900</td>\n",
       "      <td>25.543900</td>\n",
       "      <td>40.645600</td>\n",
       "      <td>44.034200</td>\n",
       "      <td>17.602700</td>\n",
       "      <td>55.450100</td>\n",
       "      <td>14.752000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.312300</td>\n",
       "      <td>1.400580</td>\n",
       "      <td>48.829100</td>\n",
       "      <td>26.624200</td>\n",
       "      <td>41.821600</td>\n",
       "      <td>44.910500</td>\n",
       "      <td>17.713900</td>\n",
       "      <td>55.284100</td>\n",
       "      <td>14.796000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.284800</td>\n",
       "      <td>1.405458</td>\n",
       "      <td>49.305700</td>\n",
       "      <td>26.945800</td>\n",
       "      <td>41.910100</td>\n",
       "      <td>46.008900</td>\n",
       "      <td>17.734700</td>\n",
       "      <td>55.332000</td>\n",
       "      <td>14.783000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.156000</td>\n",
       "      <td>1.408802</td>\n",
       "      <td>49.271600</td>\n",
       "      <td>26.830200</td>\n",
       "      <td>41.945300</td>\n",
       "      <td>45.573200</td>\n",
       "      <td>18.039100</td>\n",
       "      <td>55.352000</td>\n",
       "      <td>14.778000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.063800</td>\n",
       "      <td>1.421972</td>\n",
       "      <td>48.315800</td>\n",
       "      <td>26.333400</td>\n",
       "      <td>41.347900</td>\n",
       "      <td>44.759900</td>\n",
       "      <td>18.540300</td>\n",
       "      <td>55.331900</td>\n",
       "      <td>14.784000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.082400</td>\n",
       "      <td>1.384098</td>\n",
       "      <td>49.703100</td>\n",
       "      <td>27.081900</td>\n",
       "      <td>42.212400</td>\n",
       "      <td>45.675000</td>\n",
       "      <td>18.512200</td>\n",
       "      <td>55.800100</td>\n",
       "      <td>14.659000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.073600</td>\n",
       "      <td>1.401508</td>\n",
       "      <td>49.591200</td>\n",
       "      <td>26.843100</td>\n",
       "      <td>41.962600</td>\n",
       "      <td>45.524800</td>\n",
       "      <td>18.882600</td>\n",
       "      <td>55.540800</td>\n",
       "      <td>14.728000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.915600</td>\n",
       "      <td>1.409403</td>\n",
       "      <td>49.376400</td>\n",
       "      <td>26.646200</td>\n",
       "      <td>42.081600</td>\n",
       "      <td>45.690700</td>\n",
       "      <td>18.174800</td>\n",
       "      <td>55.533000</td>\n",
       "      <td>14.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.908700</td>\n",
       "      <td>1.419038</td>\n",
       "      <td>49.160800</td>\n",
       "      <td>27.016400</td>\n",
       "      <td>41.980100</td>\n",
       "      <td>45.421200</td>\n",
       "      <td>18.303200</td>\n",
       "      <td>55.380000</td>\n",
       "      <td>14.771000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.920900</td>\n",
       "      <td>1.394858</td>\n",
       "      <td>49.734300</td>\n",
       "      <td>27.431800</td>\n",
       "      <td>42.207400</td>\n",
       "      <td>45.981400</td>\n",
       "      <td>17.858200</td>\n",
       "      <td>55.530800</td>\n",
       "      <td>14.731000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.866800</td>\n",
       "      <td>1.450230</td>\n",
       "      <td>49.429900</td>\n",
       "      <td>26.959100</td>\n",
       "      <td>41.668400</td>\n",
       "      <td>45.597600</td>\n",
       "      <td>17.827600</td>\n",
       "      <td>55.446000</td>\n",
       "      <td>14.753000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.799100</td>\n",
       "      <td>1.437987</td>\n",
       "      <td>49.725800</td>\n",
       "      <td>27.219700</td>\n",
       "      <td>42.138400</td>\n",
       "      <td>45.735900</td>\n",
       "      <td>18.119800</td>\n",
       "      <td>55.413000</td>\n",
       "      <td>14.762000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.798400</td>\n",
       "      <td>1.446776</td>\n",
       "      <td>49.562500</td>\n",
       "      <td>27.133300</td>\n",
       "      <td>42.241000</td>\n",
       "      <td>45.726800</td>\n",
       "      <td>18.471900</td>\n",
       "      <td>55.315000</td>\n",
       "      <td>14.788000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.794800</td>\n",
       "      <td>1.438887</td>\n",
       "      <td>49.590400</td>\n",
       "      <td>26.982600</td>\n",
       "      <td>42.024000</td>\n",
       "      <td>45.692900</td>\n",
       "      <td>18.325200</td>\n",
       "      <td>55.718800</td>\n",
       "      <td>14.681000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9210, training_loss=1.144713898202107, metrics={'train_runtime': 3843.2667, 'train_samples_per_second': 2.396, 'total_flos': 7.023151183117517e+16, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 1585229824, 'init_mem_gpu_alloc_delta': 1625367040, 'init_mem_cpu_peaked_delta': 1621676032, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 3025321984, 'train_mem_gpu_alloc_delta': 6509939712, 'train_mem_cpu_peaked_delta': 411684864, 'train_mem_gpu_peaked_delta': 8868905984})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='103' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [103/103 00:57]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = trainer.predict(tokenized_datasets[\"test\"],num_beams=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[    2,     0,     0, ...,  1394,  6045,     2],\n",
      "       [    2, 24375,     8, ...,     1,     1,     1],\n",
      "       [    2,     0,     0, ...,  3045,     4,     2],\n",
      "       ...,\n",
      "       [    2,     0, 13012, ...,    30,  3213,     2],\n",
      "       [    2,     0,     0, ...,    11,  8353,     2],\n",
      "       [    2, 41415, 11210, ...,   416,  3996,     2]]), label_ids=array([[    0,   725, 25984, ...,  -100,  -100,  -100],\n",
      "       [    0, 24375,     8, ...,  -100,  -100,  -100],\n",
      "       [    0,   574, 11867, ...,  -100,  -100,  -100],\n",
      "       ...,\n",
      "       [    0, 13012,   102, ...,  -100,  -100,  -100],\n",
      "       [    0,   970,    21, ...,  -100,  -100,  -100],\n",
      "       [    0, 41415, 11210, ...,  -100,  -100,  -100]]), metrics={'eval_loss': 1.4359217882156372, 'eval_rouge1': 48.3409, 'eval_rouge2': 25.6455, 'eval_rougeL': 41.0306, 'eval_rougeLsum': 44.3759, 'eval_gen_len': 17.8181, 'eval_runtime': 59.4663, 'eval_samples_per_second': 13.773, 'test_mem_cpu_alloc_delta': -117116928, 'test_mem_gpu_alloc_delta': 0, 'test_mem_cpu_peaked_delta': 117116928, 'test_mem_gpu_peaked_delta': 2342890496})\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python333",
   "language": "python",
   "name": "emotion_fan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
