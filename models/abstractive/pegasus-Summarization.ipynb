{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric,Dataset,DatasetDict\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import AutoTokenizer\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "#datasets = [\"samsum\",\"cnn\",\"xsum\"]\n",
    "model_name = \"google/pegasus-xsum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    # Extract a few results\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset samsum (/home/weichen/.cache/huggingface/datasets/samsum/samsum/0.0.0/3f7dba43be72ab10ca66a2e0f8547b3590e96c2bd9f2cbb1f6bb1ec1f1488ba6)\n",
      "Using the latest cached version of the module from /home/weichen/.cache/huggingface/modules/datasets_modules/metrics/rouge/2b73d5eb463209373e9d21a95decb226d4164bdca4c361b8dfad295ec82bc62e (last modified on Wed Apr 28 14:00:09 2021) since it couldn't be found locally at rouge/rouge.py or remotely (ConnectionError).\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"samsum\")\n",
    "metric = load_metric(\"rouge\")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf697cd295144835a026b311833d92e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84a034db21b49c9903bccd63e2dc8f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ecbb69f72fe4b44ab8d32dca25621b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_input_length = 512\n",
    "max_target_length = 128\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [doc for doc in examples[\"dialogue\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"summary\"], max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)\n",
    "batch_size = 8\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    \"pegasus-xum-samsum\",\n",
    "    evaluation_strategy = \"steps\",\n",
    "    eval_steps = 500,\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=4,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    warmup_steps=200,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_rouge1\",\n",
    "    greater_is_better=True\n",
    ")\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='7368' max='7368' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7368/7368 1:18:37, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.602473</td>\n",
       "      <td>46.761800</td>\n",
       "      <td>22.878300</td>\n",
       "      <td>39.164100</td>\n",
       "      <td>42.711400</td>\n",
       "      <td>16.476800</td>\n",
       "      <td>141.284700</td>\n",
       "      <td>5.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.539185</td>\n",
       "      <td>49.725700</td>\n",
       "      <td>24.495600</td>\n",
       "      <td>41.074000</td>\n",
       "      <td>45.383900</td>\n",
       "      <td>20.507300</td>\n",
       "      <td>167.017600</td>\n",
       "      <td>4.898000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.504752</td>\n",
       "      <td>50.460900</td>\n",
       "      <td>25.462000</td>\n",
       "      <td>41.941600</td>\n",
       "      <td>46.029600</td>\n",
       "      <td>19.651600</td>\n",
       "      <td>162.327700</td>\n",
       "      <td>5.039000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.494941</td>\n",
       "      <td>50.191500</td>\n",
       "      <td>25.630200</td>\n",
       "      <td>41.767000</td>\n",
       "      <td>45.847200</td>\n",
       "      <td>18.946200</td>\n",
       "      <td>161.614600</td>\n",
       "      <td>5.061000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.493194</td>\n",
       "      <td>49.911100</td>\n",
       "      <td>25.999200</td>\n",
       "      <td>42.032500</td>\n",
       "      <td>45.773600</td>\n",
       "      <td>17.146700</td>\n",
       "      <td>160.998600</td>\n",
       "      <td>5.081000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.495335</td>\n",
       "      <td>50.110400</td>\n",
       "      <td>25.902600</td>\n",
       "      <td>42.132400</td>\n",
       "      <td>46.066900</td>\n",
       "      <td>17.935200</td>\n",
       "      <td>151.779000</td>\n",
       "      <td>5.389000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.508917</td>\n",
       "      <td>50.746700</td>\n",
       "      <td>26.370700</td>\n",
       "      <td>42.273500</td>\n",
       "      <td>46.687300</td>\n",
       "      <td>20.820300</td>\n",
       "      <td>169.389100</td>\n",
       "      <td>4.829000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.522761</td>\n",
       "      <td>47.175100</td>\n",
       "      <td>24.172600</td>\n",
       "      <td>39.804900</td>\n",
       "      <td>43.087900</td>\n",
       "      <td>15.249400</td>\n",
       "      <td>145.860900</td>\n",
       "      <td>5.608000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.518134</td>\n",
       "      <td>47.244800</td>\n",
       "      <td>24.372600</td>\n",
       "      <td>39.845300</td>\n",
       "      <td>43.185600</td>\n",
       "      <td>15.061100</td>\n",
       "      <td>143.449000</td>\n",
       "      <td>5.702000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.516037</td>\n",
       "      <td>47.240400</td>\n",
       "      <td>24.276100</td>\n",
       "      <td>39.854300</td>\n",
       "      <td>43.111700</td>\n",
       "      <td>15.086800</td>\n",
       "      <td>144.621700</td>\n",
       "      <td>5.656000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.513674</td>\n",
       "      <td>47.275900</td>\n",
       "      <td>24.345300</td>\n",
       "      <td>40.008000</td>\n",
       "      <td>43.189800</td>\n",
       "      <td>15.103900</td>\n",
       "      <td>145.518200</td>\n",
       "      <td>5.621000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.512375</td>\n",
       "      <td>47.244500</td>\n",
       "      <td>24.361600</td>\n",
       "      <td>40.008500</td>\n",
       "      <td>43.158400</td>\n",
       "      <td>15.009800</td>\n",
       "      <td>144.419500</td>\n",
       "      <td>5.664000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.511510</td>\n",
       "      <td>47.282300</td>\n",
       "      <td>24.371300</td>\n",
       "      <td>39.961800</td>\n",
       "      <td>43.142700</td>\n",
       "      <td>15.029300</td>\n",
       "      <td>145.160500</td>\n",
       "      <td>5.635000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.511155</td>\n",
       "      <td>47.368200</td>\n",
       "      <td>24.362400</td>\n",
       "      <td>39.992800</td>\n",
       "      <td>43.232600</td>\n",
       "      <td>15.242100</td>\n",
       "      <td>145.273100</td>\n",
       "      <td>5.631000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7368, training_loss=nan, metrics={'train_runtime': 4718.61, 'train_samples_per_second': 1.561, 'total_flos': 6.981073885384704e+16, 'epoch': 4.0, 'init_mem_cpu_alloc_delta': 1220816896, 'init_mem_gpu_alloc_delta': 2280005120, 'init_mem_cpu_peaked_delta': 1463779328, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 2706505728, 'train_mem_gpu_alloc_delta': 9117943808, 'train_mem_cpu_peaked_delta': 1948725248, 'train_mem_gpu_peaked_delta': 11142844416})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='103' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [103/103 02:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = trainer.predict(tokenized_datasets[\"test\"],num_beams=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[    0, 12195,   591, ...,     0,     0,     0],\n",
      "       [    0,  6303,   111, ...,     0,     0,     0],\n",
      "       [    0, 43880,   138, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [    0, 42828, 11586, ...,     0,     0,     0],\n",
      "       [    0,   353,   140, ...,     0,     0,     0],\n",
      "       [    0, 38772,   148, ...,     0,     0,     0]]), label_ids=array([[12636,   397, 17379, ...,  -100,  -100,  -100],\n",
      "       [ 6303,   111,  7374, ...,  -100,  -100,  -100],\n",
      "       [43880,   137,   131, ...,  -100,  -100,  -100],\n",
      "       ...,\n",
      "       [42828,  1406,   114, ...,  -100,  -100,  -100],\n",
      "       [  353,   140,   114, ...,  -100,  -100,  -100],\n",
      "       [ 9199,  9274,   114, ...,  -100,  -100,  -100]]), metrics={'eval_loss': 1.5203441381454468, 'eval_rouge1': 50.6243, 'eval_rouge2': 26.3668, 'eval_rougeL': 42.2809, 'eval_rougeLsum': 46.4494, 'eval_gen_len': 21.8059, 'eval_runtime': 150.3924, 'eval_samples_per_second': 5.446, 'test_mem_cpu_alloc_delta': 782336, 'test_mem_gpu_alloc_delta': 0, 'test_mem_cpu_peaked_delta': 1441792, 'test_mem_gpu_peaked_delta': 3808108544})\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python333",
   "language": "python",
   "name": "emotion_fan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
